# Quick Start Guide - Speech Emotion Recognition

HÆ°á»›ng dáº«n nhanh Ä‘á»ƒ cháº¡y project Speech Emotion Recognition vá»›i CREMA-D dataset.

## ğŸš€ Khá»Ÿi Ä‘á»™ng nhanh (Quick Start)

### 1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Táº¡o mÃ´i trÆ°á»ng conda
conda create -n voice-recognition python=3.9 -y
conda activate voice-recognition

# CÃ i Ä‘áº·t dependencies
cd voice
pip install -r requirements.txt
```

### 2. Kiá»ƒm tra cáº¥u hÃ¬nh

```bash
python src/config.py
```

### 3. Cháº¡y toÃ n bá»™ pipeline

```bash
# Cháº¡y full pipeline (data prep + training + evaluation)
python run_pipeline.py

# Hoáº·c cháº¡y nhanh vá»›i 10 epochs Ä‘á»ƒ test
python run_pipeline.py --quick
```

## ğŸ“‚ Cáº¥u trÃºc Project

```
voice/
â”œâ”€â”€ CREMA-D/                   # Dataset (7,442 audio files)
â”‚   â””â”€â”€ AudioWAV/
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ config.py              # Cáº¥u hÃ¬nh táº¥t cáº£
â”‚   â”œâ”€â”€ preprocess.py          # Xá»­ lÃ½ audio
â”‚   â”œâ”€â”€ dataset.py             # Load data, parse labels
â”‚   â”œâ”€â”€ data_loader.py         # Data loading & augmentation
â”‚   â”œâ”€â”€ data_preparation.py    # Data preparation pipeline
â”‚   â”œâ”€â”€ model.py               # CNN model
â”‚   â”œâ”€â”€ train.py               # Training
â”‚   â”œâ”€â”€ evaluate.py            # Evaluation
â”‚   â”œâ”€â”€ predict.py             # Inference
â”‚   â””â”€â”€ record.py              # Ghi Ã¢m tá»« mic
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ app.py                 # Streamlit web app
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploratory.ipynb      # PhÃ¢n tÃ­ch dá»¯ liá»‡u
â””â”€â”€ results/                    # Káº¿t quáº£ training
```

## ğŸ¯ CÃ¡c chá»©c nÄƒng chÃ­nh

### 1. Training Model

```bash
# CÃ¡ch 1: Cháº¡y full pipeline
python run_pipeline.py

# CÃ¡ch 2: Chá»‰ training
python src/train.py
```

### 2. Evaluation

```bash
python src/evaluate.py
```

### 3. Prediction tá»« file audio

```bash
python src/predict.py
```

Hoáº·c trong Python:

```python
from src.predict import predict_from_file

result = predict_from_file('path/to/audio.wav')
print(f"Emotion: {result['predicted_emotion']}")
print(f"Confidence: {result['confidence']:.2%}")
```

### 4. Ghi Ã¢m vÃ  dá»± Ä‘oÃ¡n

```bash
python src/record.py
```

Hoáº·c:

```python
from src.record import record_and_predict

result = record_and_predict(duration=3.0)
```

### 5. Web Demo vá»›i Streamlit

```bash
streamlit run demo/app.py
```

Sau Ä‘Ã³ má»Ÿ browser táº¡i `http://localhost:8501`

### 6. Exploratory Analysis (Jupyter)

```bash
jupyter notebook notebooks/exploratory.ipynb
```

## ğŸ“Š Káº¿t quáº£ mong Ä‘á»£i

- **Training Time**: ~30-60 phÃºt (50 epochs, GPU)
- **Accuracy**: ~60-70% trÃªn test set
- **Model Size**: ~50-100 MB

## ğŸ”§ TÃ¹y chá»‰nh

### Thay Ä‘á»•i hyperparameters

Edit `src/config.py`:

```python
BATCH_SIZE = 32
EPOCHS = 100
LEARNING_RATE = 0.001
```

### Thay Ä‘á»•i model architecture

Edit `src/model.py`:

```python
CNN_PARAMS = {
    'conv_blocks': [
        {'filters': 32, 'kernel_size': (3, 3)},
        {'filters': 64, 'kernel_size': (3, 3)},
        # ThÃªm layers...
    ]
}
```

## ğŸ¤ 6 Emotions Ä‘Æ°á»£c nháº­n diá»‡n

1. **ANG** - Anger (Giáº­n dá»¯) ğŸ˜ 
2. **HAP** - Happiness (Vui váº») ğŸ˜Š
3. **SAD** - Sadness (Buá»“n bÃ£) ğŸ˜¢
4. **NEU** - Neutral (Trung tÃ­nh) ğŸ˜
5. **DIS** - Disgust (GhÃª tá»Ÿm) ğŸ¤¢
6. **FEA** - Fear (Sá»£ hÃ£i) ğŸ˜¨

## ğŸ“ Files quan trá»ng

| File | MÃ´ táº£ |
|------|-------|
| `config.py` | Táº¥t cáº£ cáº¥u hÃ¬nh, hyperparameters |
| `train.py` | Training loop chÃ­nh |
| `model.py` | CNN architecture |
| `predict.py` | Inference tá»« file |
| `record.py` | Ghi Ã¢m realtime |
| `app.py` | Web demo |

## ğŸ› Troubleshooting

### Lá»—i: No module named 'librosa'

```bash
pip install librosa
```

### Lá»—i: Numba caching

```bash
export NUMBA_CACHE_DIR=/tmp
python src/train.py
```

### Lá»—i: GPU not found

TensorFlow sáº½ tá»± Ä‘á»™ng dÃ¹ng CPU náº¿u khÃ´ng cÃ³ GPU.

### Lá»—i: Recording khÃ´ng hoáº¡t Ä‘á»™ng

```bash
pip install sounddevice soundfile
```

## ğŸ“š TÃ i liá»‡u Ä‘áº§y Ä‘á»§

Xem `README.md` Ä‘á»ƒ biáº¿t chi tiáº¿t vá»:
- Architecture
- Dataset
- API documentation
- Advanced features

## ğŸ“ Citation

```
Cao, H., Cooper, D. G., Keutmann, M. K., Gur, R. C., Nenkova, A., & Verma, R. (2014).
CREMA-D: Crowd-sourced Emotional Multimodal Actors Dataset.
IEEE Transactions on Affective Computing, 5(4), 377-390.
```

## ğŸ’¡ Tips

1. **DÃ¹ng GPU** Ä‘á»ƒ training nhanh hÆ¡n
2. **Cache data** láº§n Ä‘áº§u sáº½ cháº­m, láº§n sau nhanh hÆ¡n
3. **Augmentation** giÃºp cáº£i thiá»‡n accuracy
4. **Batch size** nhá» hÆ¡n náº¿u bá»‹ out of memory
5. **Early stopping** tá»± Ä‘á»™ng dá»«ng khi khÃ´ng cáº£i thiá»‡n

---

**ChÃºc báº¡n thÃ nh cÃ´ng! ğŸ‰**

