# ğŸš€ HÆ°á»›ng dáº«n Cháº¡y Project

## âœ… Cleanup Ä‘Ã£ hoÃ n thÃ nh

ÄÃ£ xÃ³a 2 files trÃ¹ng láº·p:
- âŒ `src/data_loader.py` (Ä‘Ã£ cÃ³ trong `preprocess.py`)
- âŒ `src/data_preparation.py` (Ä‘Ã£ cÃ³ trong `train.py`)

ÄÃ£ Ä‘á»“ng bá»™ hÃ³a táº¥t cáº£ imports vÃ  paths!

---

## ğŸ“‹ BÆ°á»›c 1: Test Imports (QUAN TRá»ŒNG!)

Cháº¡y test script Ä‘á»ƒ Ä‘áº£m báº£o má»i thá»© hoáº¡t Ä‘á»™ng:

```bash
cd /Users/macbook/Library/CloudStorage/OneDrive-SwinburneUniversity/Documents/Project/voice
conda activate voice-recognition
python test_imports.py
```

**Káº¿t quáº£ mong Ä‘á»£i:**
```
âœ… ALL TESTS PASSED!

You can now run the pipeline:
  python run_pipeline.py --quick
```

---

## ğŸ“‹ BÆ°á»›c 2: Cháº¡y Pipeline

### Option 1: Quick Test (10 epochs - ~10-15 phÃºt) ğŸ¯ KHUYáº¾N NGHá»Š

```bash
python run_pipeline.py --quick
```

Sáº½ thá»±c hiá»‡n:
1. Load 7,442 audio files tá»« `data/CREMA-D/AudioWAV/`
2. Preprocess â†’ Mel spectrograms (128 bands)
3. Train CNN vá»›i 10 epochs
4. In ra test accuracy

### Option 2: Full Training (50 epochs - ~45-60 phÃºt)

```bash
python run_pipeline.py --epochs 50
```

### Option 3: Custom

```bash
python run_pipeline.py --epochs 20 --batch-size 16
```

---

## ğŸ“Š Káº¿t quáº£ mong Ä‘á»£i

```
======================================================================
SPEECH EMOTION RECOGNITION - FULL PIPELINE
======================================================================

[1/1] MODEL TRAINING & EVALUATION
----------------------------------------------------------------------
Audio directory: /Users/.../data/CREMA-D/AudioWAV
Found WAV files: 7442

============================================================
Speech Emotion Recognition - CREMA-D Dataset
============================================================

[1/4] Loading and preprocessing audio files...
Processing audio files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7442/7442 [XX:XX<00:00]

Dataset shape: (7442, 128, 216, 1)
Labels shape: (7442,)
Number of classes: 6

Class distribution:
  ANG: 1271
  DIS: 1271
  FEA: 1271
  HAP: 1636
  NEU: 1087
  SAD: 1271

[2/4] Splitting dataset...
Train set: XXXX samples
Validation set: XXXX samples
Test set: XXXX samples

[3/4] Creating model...
[4/4] Training model...

Epoch 1/10
...

Test Accuracy: X.XXXX (XX.XX%)
Test Loss: X.XXXX

Per-class accuracy on test set:
  ANG: X.XXXX (XX.XX%)
  DIS: X.XXXX (XX.XX%)
  FEA: X.XXXX (XX.XX%)
  HAP: X.XXXX (XX.XX%)
  NEU: X.XXXX (XX.XX%)
  SAD: X.XXXX (XX.XX%)

======================================================================
PIPELINE COMPLETED SUCCESSFULLY!
======================================================================

Model saved to: best_model.keras
```

---

## ğŸ” Troubleshooting

### Lá»—i: "AudioWAV directory not found"

```bash
# Check Ä‘Æ°á»ng dáº«n
python -c "import sys; sys.path.append('src'); from config import AUDIO_WAV_DIR; print(AUDIO_WAV_DIR); print(AUDIO_WAV_DIR.exists())"

# NÃªn tháº¥y:
# /Users/.../voice/data/CREMA-D/AudioWAV
# True
```

### Lá»—i: "No module named 'librosa'"

```bash
pip install -r requirements.txt
```

### Lá»—i: Import errors

```bash
# Run test script
python test_imports.py

# Sáº½ cho biáº¿t module nÃ o bá»‹ lá»—i
```

### Lá»—i: TensorFlow mutex lock

ÄÃ¢y lÃ  lá»—i thÃ´ng thÆ°á»ng cá»§a TensorFlow trÃªn macOS, khÃ´ng áº£nh hÆ°á»Ÿng chá»©c nÄƒng.
Chá»‰ cáº§n cháº¡y láº¡i hoáº·c dÃ¹ng `NUMBA_CACHE_DIR=/tmp`:

```bash
NUMBA_CACHE_DIR=/tmp python run_pipeline.py --quick
```

---

## ğŸ“ Files cÃ²n láº¡i sau Cleanup

```
voice/
â”œâ”€â”€ src/                           âœ… 9 Python files
â”‚   â”œâ”€â”€ config.py                  â†’ Central configuration
â”‚   â”œâ”€â”€ preprocess.py              â†’ Audio processing  
â”‚   â”œâ”€â”€ dataset.py                 â†’ Dataset management
â”‚   â”œâ”€â”€ model.py                   â†’ CNN architecture
â”‚   â”œâ”€â”€ train.py                   â†’ Training logic
â”‚   â”œâ”€â”€ evaluate.py                â†’ Evaluation
â”‚   â”œâ”€â”€ predict.py                 â†’ Inference
â”‚   â””â”€â”€ record.py                  â†’ Audio recording
â”‚
â”œâ”€â”€ run_pipeline.py                âœ… Main runner
â”œâ”€â”€ test_imports.py                âœ… Test script
â”œâ”€â”€ requirements.txt               âœ… Dependencies
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ CREMA-D/
â”‚       â””â”€â”€ AudioWAV/              âœ… 7,442 .wav files
â”‚
â”œâ”€â”€ README.md                      ğŸ“š Full documentation
â”œâ”€â”€ QUICKSTART.md                  ğŸ“š Quick start (Vietnamese)
â”œâ”€â”€ CLEANUP_SUMMARY.md             ğŸ“š Cleanup details
â””â”€â”€ RUN_GUIDE.md                   ğŸ“š This file
```

---

## ğŸ¯ CÃ¡c lá»‡nh há»¯u Ã­ch

```bash
# Test config
python src/config.py

# Test preprocessing 1 file
python src/preprocess.py

# Train trá»±c tiáº¿p (khÃ´ng qua pipeline)
python src/train.py

# Test prediction
python src/predict.py path/to/audio.wav

# Record vÃ  predict real-time
python src/record.py

# Web demo
streamlit run demo/app.py

# Explore dataset
jupyter notebook notebooks/exploratory.ipynb
```

---

## ğŸ’¡ Tips

1. **Láº§n Ä‘áº§u cháº¡y**: DÃ¹ng `--quick` Ä‘á»ƒ test (10-15 phÃºt)
2. **Preprocessing lÃ¢u**: Preprocessing 7,442 files máº¥t ~5-10 phÃºt (chá»‰ láº§n Ä‘áº§u)
3. **Save model**: Model tá»± Ä‘á»™ng save vÃ o `best_model.keras`
4. **Monitor training**: CÃ³ thá»ƒ dÃ¹ng TensorBoard náº¿u enable trong callbacks
5. **Memory**: Cáº§n ~4-8GB RAM Ä‘á»ƒ load toÃ n bá»™ dataset

---

## âœ… Checklist trÆ°á»›c khi cháº¡y

- [ ] Conda environment activated: `voice-recognition`
- [ ] All requirements installed: `pip install -r requirements.txt`
- [ ] Test imports passed: `python test_imports.py`
- [ ] Audio directory exists: 7,442 WAV files
- [ ] Enough disk space: ~500MB cho model + logs

---

**Ready to go!** ğŸš€

Cháº¡y ngay:
```bash
python test_imports.py && python run_pipeline.py --quick
```

